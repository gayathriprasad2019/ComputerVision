{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1836c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp39-cp39-win_amd64.whl (35.1 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\gayathri\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089cfcd",
   "metadata": {},
   "source": [
    "The first step is to find the path to the “haarcascade_frontalface_alt2.xml” and “haarcascade_eye_tree_eyeglasses.xml” files.\n",
    "We do this by using the os module of Python language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3ae333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "cascPathface = os.path.dirname(cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "cascPatheyes = os.path.dirname(cv2.__file__) + \"/data/haarcascade_eye_tree_eyeglasses.xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7924d655",
   "metadata": {},
   "source": [
    "The next step is to load our classifier. We are using two classifiers, one for detecting the face and others for detection eyes. The path to the above XML file goes as an argument to CascadeClassifier() method of OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1d06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cascPathface)\n",
    "eyeCascade = cv2.CascadeClassifier(cascPatheyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889f161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the webcam\n",
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373332fb",
   "metadata": {},
   "source": [
    "Next, we need to get the frames from the webcam stream, we do this using the read() function. We use the infinite loop to get all the frames until the time we want to close the stream.\n",
    "The read() function returns:\n",
    "\n",
    "The actual video frame read (one frame on each loop)\n",
    "A return code\n",
    "\n",
    "The return code tells us if we have run out of frames, which will happen if we are reading from a file. This doesn’t matter when reading from the webcam since we can record forever, so we will ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "#to convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,\n",
    "                                         scaleFactor=1.1,\n",
    "                                         minNeighbors=5,\n",
    "                                         minSize=(60, 60),\n",
    "                                         flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h),(0,255,0), 2)\n",
    "        faceROI = frame[y:y+h,x:x+w]\n",
    "        eyes = eyeCascade.detectMultiScale(faceROI)\n",
    "        for (x2, y2, w2, h2) in eyes:\n",
    "            eye_center = (x + x2 + w2 // 2, y + y2 + h2 // 2)\n",
    "            radius = int(round((w2 + h2) * 0.25))\n",
    "            frame = cv2.circle(frame, eye_center, radius, (255, 0, 0), 4)\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "#to clean up and release the picture.\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d21817",
   "metadata": {},
   "source": [
    "The faceCascade object has a method detectMultiScale(), which receives a frame(image) as an argument and runs the classifier cascade over the image. The term MultiScale indicates that the algorithm looks at subregions of the image in multiple scales, to detect faces of varying sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc91b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d2da03",
   "metadata": {},
   "source": [
    "scaleFactor – Parameter specifying how much the image size is reduced at each image scale. By rescaling the input image, you can resize a larger face to a smaller one, making it detectable by the algorithm. 1.05 is a good possible value for this, which means you use a small step for resizing, i.e. reduce the size by 5%, you increase the chance of a matching size with the model for detection is found.\n",
    "minNeighbors – Parameter specifying how many neighbours each candidate rectangle should have to retain it. This parameter will affect the quality of the detected faces. Higher value results in fewer detections but with higher quality. 3~6 is a good value for it.\n",
    "flags –Mode of operation\n",
    "minSize – Minimum possible object size. Objects smaller than that are ignored.\n",
    "\n",
    "The variable faces now contain all the detections for the target image. Detections are saved as pixel coordinates. Each detection is defined by its top-left corner coordinates and width and height of the rectangle that encompasses the detected face.\n",
    "\n",
    "To show the detected face, we will draw a rectangle over it.OpenCV’s rectangle() draws rectangles over images, and it needs to know the pixel coordinates of the top-left and bottom-right corner. The coordinates indicate the row and column of pixels in the image. We can easily get these coordinates from the variable face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f839a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcf07170",
   "metadata": {},
   "source": [
    "The function rectangle() accepts the following arguments:\n",
    "\n",
    "The original image\n",
    "The coordinates of the top-left point of the detection\n",
    "The coordinates of the bottom-right point of the detection\n",
    "The colour of the rectangle (a tuple that defines the amount of red, green, and blue (0-255)).In our case, we set as green just keeping the green component as 255 and rest as zero.\n",
    "The thickness of the rectangle lines\n",
    "Next, we just display the resulting frame and also set a way to exit this infinite loop and close the video feed. By pressing the ‘q’ key, we can exit the script here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34bf91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85064891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "# Load the cascade\n",
    "cascPathface = os.path.dirname(cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(cascPathface)\n",
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Read the input image\n",
    "img = cv2.imread('frnds.jpg')\n",
    "# Convert into grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "# Draw rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "# Display the output\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48136b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c970c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the cascade\n",
    "face_cascade = cv2.CascadeClassifier(cascPathface)\n",
    "\n",
    "# To capture video from webcam. \n",
    "cap = cv2.VideoCapture(0)\n",
    "# To use a video file as input \n",
    "# cap = cv2.VideoCapture('filename.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Display\n",
    "    cv2.imshow('img', img)\n",
    "    # Stop if escape key is pressed\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k==27:\n",
    "        break\n",
    "# Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444f0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
